# ğŸ”§ SoluciÃ³n de Problemas

Soluciones a los errores mÃ¡s comunes.

## âŒ Error: "No module named 'typing_extensions'"

### SoluciÃ³n:
```bash
# AsegÃºrate de estar en el entorno virtual
source venv/bin/activate

# Instala las dependencias en orden
pip install --upgrade pip
pip install typing-extensions
pip install click
pip install ddgs
```

### Si persiste el error:
```bash
# Borra el entorno virtual y crÃ©alo de nuevo
deactivate
rm -rf venv
python3 -m venv venv
source venv/bin/activate

# Ejecuta el instalador automÃ¡tico
python install.py
```

## âŒ Error: "Ollama no estÃ¡ instalado"

### SoluciÃ³n para macOS:
1. Ve a https://ollama.com/download
2. Descarga "Ollama-darwin.zip"
3. Descomprime y arrastra a Aplicaciones
4. Abre Ollama desde Aplicaciones
5. Verifica: `ollama --version`

### Si Ollama no responde:
```bash
# En macOS, asegÃºrate de que Ollama estÃ© corriendo
# Busca el icono de Ollama en la barra de menÃº (arriba a la derecha)

# Si no estÃ¡, abre la aplicaciÃ³n Ollama
open -a Ollama

# Espera unos segundos y prueba de nuevo
ollama --version
```

## âŒ Error: "No hay modelos disponibles"

### SoluciÃ³n:
```bash
# Instala el modelo
ollama pull llama3.2

# Verifica que se instalÃ³
ollama list

# DeberÃ­as ver algo como:
# NAME            ID              SIZE    MODIFIED
# llama3.2:latest  a80c4f17acd5    2.0 GB  2 hours ago
```

### Si la descarga falla:
```bash
# Intenta con un modelo mÃ¡s pequeÃ±o primero
ollama pull llama3.2:1b

# O prueba con otro modelo
ollama pull phi3
```

## âŒ Error: "Command not found: ollama"

### SoluciÃ³n para macOS:
```bash
# Verifica si Ollama estÃ¡ instalado
ls /Applications/Ollama.app

# Si existe pero no se encuentra el comando, aÃ±ade al PATH
echo 'export PATH="/Applications/Ollama.app/Contents/MacOS:$PATH"' >> ~/.zshrc
source ~/.zshrc

# Si usas bash en lugar de zsh:
echo 'export PATH="/Applications/Ollama.app/Contents/MacOS:$PATH"' >> ~/.bash_profile
source ~/.bash_profile
```

## âŒ Error: "pip: command not found"

### SoluciÃ³n:
```bash
# En macOS, usa pip3
pip3 install -r requirements.txt

# O especifica python3 explÃ­citamente
python3 -m pip install -r requirements.txt
```

## âŒ Error en la bÃºsqueda web (DuckDuckGo)

### Si ves: "RuntimeWarning: This package has been renamed to `ddgs`"

**SoluciÃ³n:**
```bash
# Desinstala el paquete antiguo
pip uninstall duckduckgo-search -y

# Instala el nuevo paquete
pip install ddgs
```

### Si persiste el error:
```bash
# Reinstala desde cero
pip uninstall ddgs -y
pip install --upgrade ddgs
```

## âŒ El agente es muy lento

### Soluciones:

**1. Usa un modelo mÃ¡s pequeÃ±o:**
```bash
# En agent.py, cambia el modelo a uno mÃ¡s pequeÃ±o
ollama pull llama3.2:1b  # Solo 1.3GB, mucho mÃ¡s rÃ¡pido
```

Luego en `agent.py` lÃ­nea 12:
```python
def __init__(self, model="llama3.2:1b"):  # Cambiar aquÃ­
```

**2. Verifica que Ollama use tu GPU (si tienes):**
```bash
# Mientras el agente estÃ¡ corriendo, en otra terminal:
ollama ps

# DeberÃ­as ver informaciÃ³n sobre el uso de GPU
```

**3. Cierra otras aplicaciones** para liberar RAM

## âŒ Error: "Python version incompatible"

### SoluciÃ³n:
```bash
# Verifica tu versiÃ³n de Python
python3 --version

# Necesitas Python 3.9 o superior
# En macOS 12.7.6, puedes instalar una versiÃ³n mÃ¡s nueva:

# OpciÃ³n 1: Con Homebrew
brew install python@3.11

# OpciÃ³n 2: Descarga de python.org
# Ve a: https://www.python.org/downloads/
# Descarga Python 3.11 para macOS

# Luego usa python3.11 en lugar de python3
python3.11 -m venv venv
```

## âš ï¸ Problemas especÃ­ficos de macOS 12.7.6

### Si tienes macOS 12.7.6:

```bash
# 1. AsegÃºrate de usar python3 (no python)
python3 --version

# 2. Instala Xcode Command Line Tools si no los tienes
xcode-select --install

# 3. Actualiza pip
python3 -m pip install --upgrade pip

# 4. Usa python3 explÃ­citamente en todos los comandos
python3 -m venv venv
python3 install.py
python3 test_agent.py
python3 run_agent.py "tu pregunta"
```

## ğŸ†˜ Si nada funciona

### ReinstalaciÃ³n completa:

```bash
# 1. Borra todo
deactivate  # Si estÃ¡s en un venv
cd ..
rm -rf deepagents-research-assistant
rm -rf ~/Library/Application\ Support/Ollama  # Borra datos de Ollama

# 2. Desinstala Ollama
# Arrastra Ollama.app a la Papelera
# Reinicia tu Mac

# 3. Empieza de cero
# Descarga el proyecto de nuevo
# Sigue la OpciÃ³n A (InstalaciÃ³n AutomÃ¡tica) del README
```

## ğŸ“ Obtener ayuda

Si sigues teniendo problemas:

1. **Ejecuta esto y copia el output:**
```bash
python3 --version
ollama --version
ollama list
pip list | grep -E "ddgs|typing|click"
```

2. **Abre un Issue en GitHub** con:
   - Tu sistema operativo y versiÃ³n
   - El output del comando de arriba
   - El error completo que estÃ¡s viendo

## âœ… VerificaciÃ³n Final

Cuando todo estÃ© funcionando, deberÃ­as ver esto:

```bash
$ python test_agent.py
============================================================
ğŸ§ª PRUEBAS DEL AGENTE DE INVESTIGACIÃ“N
============================================================
ğŸ” Verificando Ollama...
   âœ… Ollama instalado correctamente
   
ğŸ” Verificando modelos de Ollama...
   âœ… Modelos disponibles: gemma2:4b, llama3.2, phi3
   
ğŸ” Verificando dependencias Python...
   âœ… ddgs instalado
   
ğŸ” Probando bÃºsqueda web...
   âœ… BÃºsqueda web funcionando
   
ğŸ” Probando el agente completo...
   â„¹ï¸  Usando modelo: gemma2:4b
   âœ… Agente inicializado correctamente
   ğŸ’­ Probando con una pregunta simple...
   âœ… Respuesta recibida: Hola...
   
============================================================
ğŸ“Š RESUMEN
============================================================
âœ… Ollama
âœ… Modelo
âœ… Dependencias
âœ… BÃºsqueda Web
âœ… Agente

============================================================
ğŸ‰ Â¡TODO FUNCIONA! EstÃ¡s listo para usar el agente.
```

**Nota:** El agente usarÃ¡ automÃ¡ticamente el primer modelo que encuentre instalado (como tu `gemma2:4b`). No necesitas configurar nada.
