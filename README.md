# ğŸ¤– DeepAgents Research Assistant

Un agente de investigaciÃ³n AI gratuito.


## ğŸ¯ Â¿QuÃ© hace este proyecto?

Este agente puede:
- ğŸ” Buscar informaciÃ³n en internet
- ğŸ’­ Analizar y sintetizar resultados
- ğŸ“ Generar respuestas completas
- ğŸ’¯ Todo 100% gratis

**âœ¨ Funciona con cualquier modelo de Ollama** - No necesitas un modelo especÃ­fico. El agente detecta automÃ¡ticamente el modelo que tienes instalado (como `llama3.2`, `gemma3`, `phi3`, etc.)

## ğŸ“‹ Lo que necesitas

- Python 3.9 o superior
- 8GB de RAM (16GB recomendado)
- 10GB de espacio en disco
- Internet (solo para bÃºsquedas web)

## ğŸš€ InstalaciÃ³n 

### OpciÃ³n A: InstalaciÃ³n AutomÃ¡tica (Recomendada)

```bash
# 1. Descomprimir el proyecto
cd deepagents-research-assistant

# 2. Crear entorno virtual
python3 -m venv venv

# 3. Activar entorno virtual
# En Mac/Linux:
source venv/bin/activate
# En Windows:
venv\Scripts\activate

# 4. Ejecutar instalador automÃ¡tico
python install.py
```

El script `install.py` instalarÃ¡ todo automÃ¡ticamente. Â¡Solo espera!

### OpciÃ³n B: InstalaciÃ³n Manual

Si prefieres hacerlo paso a paso:

**Paso 1: Crear entorno virtual**
```bash
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

**Paso 2: Instalar dependencias**
```bash
pip install --upgrade pip
pip install typing-extensions click ddgs
```

**Paso 3: Instalar Ollama**
- Ve a https://ollama.com/download
- Descarga para tu sistema operativo (macOS, Windows, Linux)
- Instala el programa

**Paso 4: Descargar un modelo**

Puedes usar **cualquier modelo** de Ollama. Ejemplos:

```bash
# OpciÃ³n 1: Llama (recomendado)
ollama pull llama3.2

# OpciÃ³n 2: Gemma (de Google, muy eficiente)
ollama pull gemma3:4b

# OpciÃ³n 3: Phi (de Microsoft, compacto)
ollama pull phi3

# OpciÃ³n 4: Mistral (mÃ¡s potente)
ollama pull mistral
```

**El agente detecta automÃ¡ticamente el modelo que instales.** No necesitas configurar nada. Ver [MODELS.md](MODELS.md) para mÃ¡s detalles.

**Paso 5: Verificar instalaciÃ³n**
```bash
python test_agent.py
```

## âœ… Probar que funciona

Ejecuta el script de prueba:

```bash
python test_agent.py
```

DeberÃ­as ver algo como:

```
âœ… Ollama instalado
âœ… Modelo gemma3:4b disponible
âœ… BÃºsqueda web funcionando
ğŸš€ Todo listo para usar!

Probando el agente con una pregunta simple...
Respuesta: [El agente responderÃ¡ aquÃ­]
```

## ğŸ“– CÃ³mo usar

### Uso bÃ¡sico en lÃ­nea de comandos

```bash
python run_agent.py "Â¿QuÃ© es la inteligencia artificial?"
```

### Uso en tu cÃ³digo Python

```python
from agent import ResearchAgent

# Crear el agente
agent = ResearchAgent()

# Hacer una pregunta
respuesta = agent.research("Â¿QuÃ© es machine learning?")
print(respuesta)
```

## ğŸ“ Estructura del proyecto

```
deepagents-research-assistant/
â”‚
â”œâ”€â”€ agent.py                # El agente principal (cÃ³digo simple)
â”œâ”€â”€ search.py               # BÃºsqueda web gratuita
â”œâ”€â”€ run_agent.py           # Script para lÃ­nea de comandos
â”œâ”€â”€ test_agent.py          # Script de prueba
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ README.md              # Este archivo
â””â”€â”€ examples/              # Ejemplos de uso
    â””â”€â”€ example.py
```

## ğŸ”§ SoluciÃ³n de problemas

### "Ollama no estÃ¡ instalado"
```bash
# Verifica la instalaciÃ³n
ollama --version

# Si no estÃ¡ instalado, descarga de:
# https://ollama.com/download
```

### "No hay modelos disponibles"
```bash
# Instala el modelo
ollama pull gemma3:4b

# Verifica que se instalÃ³
ollama list
```

### "Error de importaciÃ³n"
```bash
# AsegÃºrate de estar en el entorno virtual
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

# Reinstala dependencias
pip install -r requirements.txt
```

## ğŸ’¡ Ejemplos

### Ejemplo 1: Pregunta simple
```bash
python run_agent.py "Â¿QuÃ© es Python?"
```

### Ejemplo 2: InvestigaciÃ³n mÃ¡s profunda
```bash
python run_agent.py "Explica las diferencias entre machine learning y deep learning"
```

### Ejemplo 3: Usar en tu cÃ³digo
```python
from agent import ResearchAgent

agent = ResearchAgent()

preguntas = [
    "Â¿QuÃ© es blockchain?",
    "Â¿CÃ³mo funciona el machine learning?",
    "Â¿QuÃ© son las redes neuronales?"
]

for pregunta in preguntas:
    print(f"\nâ“ {pregunta}")
    respuesta = agent.research(pregunta)
    print(f"ğŸ’¬ {respuesta}\n")
```

## ğŸ“Š Costos

- âœ… Software: **0â‚¬**
- âœ… Modelos AI: **0â‚¬**
- âœ… BÃºsquedas web: **0â‚¬**
- âœ… Uso ilimitado: **0â‚¬**

**Total: 0â‚¬ para siempre** ğŸ‰

## ğŸ¤ Contribuir

Â¿Quieres mejorar el proyecto? Â¡Genial!

1. Fork el repositorio
2. Crea una rama: `git checkout -b mi-mejora`
3. Haz commit: `git commit -m "Agrego X funcionalidad"`
4. Push: `git push origin mi-mejora`
5. Abre un Pull Request

## ğŸ“„ Licencia

MIT License - Ãšsalo como quieras

## ğŸ†˜ Â¿Necesitas ayuda?

- ğŸ“– Lee este README completo
- ğŸ› Abre un Issue en GitHub
- ğŸ’¬ Pregunta en las Discussions del repo

## â­ Si te gusta el proyecto

Dale una estrella â­ en GitHub y compÃ¡rtelo con otros!

